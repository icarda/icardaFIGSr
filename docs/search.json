[{"path":[]},{"path":"/articles/CropData.html","id":"getcrops","dir":"Articles","previous_headings":"Functions","what":"getCrops()","title":"Accessing Crop-Related Data","text":"getCrops() retrieves list crop names corresponding codes.","code":""},{"path":"/articles/CropData.html","id":"getaccessions","dir":"Articles","previous_headings":"Functions","what":"getAccessions()","title":"Accessing Crop-Related Data","text":"getAccessions() returns passport data accessions specified crop list accession numbers. retrieved passport descriptors include: IG: Accession number, unique identifier accessions within genebank. Crop: Crop name associated accession. Taxon name: Scientific name sample composed genus+species. Country: 3-letter ISO 3166-1 code sample’s country origin. PopulationType: Biological status sample. SiteCode: Code identifying specific site collection. Longitude: Longitude collecting site decimal degrees format. Latitude: Latitude collecting site decimal degrees format. Altitude: Altitude collecting site. Province: Name administrative division country level. ADM1: First level administrative division country. SITE: Locality sample collected. CollectionYear: Year sample collected.","code":""},{"path":"/articles/CropData.html","id":"gettraits","dir":"Articles","previous_headings":"Functions","what":"getTraits()","title":"Accessing Crop-Related Data","text":"getTraits() returns dataframe specified crop describing available traits ontologies. dataframe includes: Id: unique identifier trait associated crop. Trait: trait name measured observed (e.g., ‘Days heading’). Options: Code-value pairs coded traits (e.g., ‘1-Narrow; 2-Medium; 3-Large’ flag leaf width trait). Field: abbreviated name trait.","code":""},{"path":"/articles/CropData.html","id":"gettraitsdata","dir":"Articles","previous_headings":"Functions","what":"getTraitsData()","title":"Accessing Crop-Related Data","text":"getTraitsData() returns observed values specified trait list accession numbers.","code":""},{"path":"/articles/CropData.html","id":"getonset","dir":"Articles","previous_headings":"Functions","what":"getOnset()","title":"Accessing Crop-Related Data","text":"getOnset() extracts daily values climatic variables based Onset Planting sites available ICARDA Genebank database. variable 365 values day (onset) year beginning planting day.","code":""},{"path":"/articles/CropData.html","id":"getgrowthperiod","dir":"Articles","previous_headings":"Functions","what":"getGrowthPeriod()","title":"Accessing Crop-Related Data","text":"getGrowthPeriod() calculates growing degree days (GDD), cumulative GDD, length growth stages various crops using onset data getOnset() function.","code":""},{"path":[]},{"path":"/articles/CropData.html","id":"passport-data","dir":"Articles","previous_headings":"Examples","what":"Passport Data","title":"Accessing Crop-Related Data","text":"","code":"# Load icardaFIGSr package library(icardaFIGSr)  # List all crops maintained in the ICARDA Genebank getCrops()  # Get all the cultivated barley accessions and their basic passport data getAccessions(crop = 'barley')  # Include DOI, taxonomy, collection year and other identifiers to the output  getAccessions(crop = 'barley', doi = TRUE, taxon = TRUE, collectionYear = TRUE, other_id = TRUE)  # Get only available accessions for distribution for barley getAccessions(crop = 'barley', available = TRUE)  # Get only georefenced accessions for barley getAccessions(crop = 'barley', coor = TRUE)  # Get accessions for barley and for which countries of origin are Morocco and Lebanon getAccessions(crop = 'barley', ori = c('MAR','LBN'))  # Get the passport data of a list of accession numbers, i.e. IGs # read the list of IGs from a csv file with a column holding IGs named e.g. IG list_IGs <- read.csv('/path/to/csv/file.csv') getAccessions(IG = list_IGs$IG) library('icardaFIGSr')  # Load FIGS subset for wheat sodicity resistance data(FIGS)  # World Map showing collecting sites of accessions mapAccessions(df = FIGS, long = 'Longitude', lat = 'Latitude') # Plotting collecting sites of accessions with points coloured based on a gradient scale of SodicityIndex values mapAccessions(FIGS, long = 'Longitude', lat = 'Latitude', y = 'SodicityIndex') # Plotting collecting sites of accessions with points coloured based on levels of y  mapAccessions(FIGS, long = 'Longitude', lat = 'Latitude', y = 'PopulationType')"},{"path":"/articles/CropData.html","id":"traits-data","dir":"Articles","previous_headings":"Examples","what":"Traits Data","title":"Accessing Crop-Related Data","text":"","code":"# To get data of one trait for a list of accessions: # Get the list of accessions for a crop of interest, e.g. barley: barley_accs <- getAccessions(crop = 'barley')  # Get traits descriptors for barley getTraits(crop = 'barley')  # Pick the traitID of the trait of interest from the output of getTraits (e.g. Awn roughness has traitID=83 for barley), and then get the trait observations getTraitsData(IG = barley_accs$IG, traitID = 83)  # To get data for many traits at once, e.g. Awn roughness (traitID=83), Plant height (traitID=93) and Days to heading (traitID=89) # Define the traits of interest traits <- c(83,93,89) # Initialize an empty list to store the results Barley_Accessions_Traits <- list()  # Loop through each TraitID for (trait_id in 1:length(traits)){   # Extract trait data for the current TraitID   trait_data <- getTraitsData(IG = barley_accs$IG,                                 traitID = traits[trait_id])    if(nrow(trait_data)<1){     next   }    # Check if the trait_data contains 'IG', 'YEAR' and a trait-specific    if (all(c(\"IG\", \"YEAR\") %in% colnames(trait_data))){     # Extract 'IG', 'YEAR', and the last column (trait-specific column)     last_col <- colnames(trait_data)[ncol(trait_data)]     trait_data <- trait_data[ ,c(\"IG\",\"YEAR\", last_col)]          # Add Trait_name column     trait_data$Trait_name <- last_col          # Rename trait_value     colnames(trait_data) <- c(\"IG\",\"Year\",\"Trait_value\",\"Trait_name\")   }   # Store the result in the list   Barley_Accessions_Traits[[as.character(trait_id)]] <- trait_data }  # Bind all datasets together (converting a list into a dataframe) Barley_Accessions_Traits <- do.call(rbind.data.frame,                                     Barley_Accessions_Traits)"},{"path":"/articles/CropData.html","id":"onset-data","dir":"Articles","previous_headings":"Examples","what":"Onset Data","title":"Accessing Crop-Related Data","text":"getOnset returns list 2 main datasets. first dataset contains site’s code first column 365 columns corresponding day year specified climate variables starting onset date. cv=TRUE, third dataset added final output contains coefficient variation variable interest.  example , use site codes durumWC dataset, specify ICDW (durum wheat) crop code (use getCrops() function list available cropCodes crop interest), specify c('tavg','prec') climate variables. Please refer documentation using ?getOnset details.","code":"library(icardaFIGSr) # Load durumWC dataset data(\"durumWC\") durumWC <- durumWC |> dplyr::ungroup()  # Get site codes Sites <- levels(as.factor(durumDaily$site_code))  # Get onset data onset <- getOnset(sites = Sites[1:2], crop = 'ICDW',                      var = c('tavg','prec'), cv = TRUE)  # Get the dataframe with climatic variables from the list object  onset.clim <- onset[[1]]  # Get the dataframe with phenological variables from the list object onset.pheno <- onset[[2]]  # Get the dataframe with coefficient of variation from the list object onset.climcv <- onset[[3]]"},{"path":"/articles/CropData.html","id":"growth-period-data","dir":"Articles","previous_headings":"Examples","what":"Growth Period Data","title":"Accessing Crop-Related Data","text":"getGrowthPeriod() returns list three dataframes: Growth_Period: contains sitecode, onset, lengths growth stages (expressed days), Cycle sum growth stages.  growth stages named following abbreviation codes crop. glossary used growth stage codes corresponding names. Onset_Data: contains sitecode, onset growth stages sites available specified crop. Growing_Degree_Days: includes sitecode, temperature ranges tmin tmax, calculated growing degree days gdd, cumulatives cumgdd corresponding days planting.","code":"library(icardaFIGSr) data(durumDaily)  # Get site codes Sites <- levels(as.factor(durumDaily$site_code))  # Get growth period for durum wheat with specified temperature range growth <- icardaFIGSr::getGrowthPeriod(sitecode = Sites,                               crop = 'Durum wheat', base = 0,                               max = 35, gdd = TRUE)  # Get the dataframe with lengths of growth stages from the returned list growth.lengths <- growth[[1]]  # Get the dataframe with phenological variables from the returned list growth.pheno <- growth[[2]]  # Get dataframe with GDD, cumulative GDD, tmin and tmax from the returned list (when gdd = TRUE) growth.gdd <- growth[[3]]"},{"path":"/articles/ML_Workflows.html","id":"binary-classification-balanced-data","dir":"Articles","previous_headings":"","what":"Binary classification: balanced data","title":"Predictive Modeling using tuneTrain()","text":"septoriaDurumWC dataset used illustrate binary classification balanced data. dataset includes monthly data 3 climatic variables (tmin, tmax precipitation), 19 bioclimatic variables evaluation durum wheat accessions Septoria Tritici. response Septoria Tritici labeled R Resistant S Susceptible. R (Resistant): represents samples/observations resistant Septoria. level indicates wheat genotypes environmental conditions Septoria’s impact minimal absent. S (Susceptible): represents samples/observations susceptible Septoria. level indicates wheat genotypes environmental conditions Septoria’s impact significant. Let’s explore results.. Class Probabilities ST_S using KNN Roc Plot ST_S using KNN Variable Importance ST_S using KNN Note difference Model Training Tuning objects end output. final hyperparameter value different (6 vs 7).","code":"library(icardaFIGSr) library(dplyr) library(pROC) library(caret)  # Load data sample data(\"septoriaDurumWC\")  # Check data is balanced septoriaDurumWC |>   count(ST_S) #> # A tibble: 2 × 2 #>   ST_S      n #>   <fct> <int> #> 1 R       106 #> 2 S        94  ## Run binary classification of ST_S with balanced data knn.ST_S <- tuneTrain(data = as.data.frame(septoriaDurumWC),                       y =  'ST_S',                       method = 'knn', # using knn algorithm                       summary = multiClassSummary, # Important for classification tasks                       repeats = 3,                       classProbs = TRUE) # also important for classification tasks #> k-Nearest Neighbors  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 127, 128, 128, 127, 126, 126, ...  #> Resampling results across tuning parameters: #>  #>   k   logLoss    AUC        prAUC      Accuracy   Kappa      F1        #>    5  2.2616126  0.6500709  0.4828789  0.6260562  0.2572795  0.6009026 #>    7  1.4423420  0.6460530  0.5016384  0.6289377  0.2653482  0.5986522 #>    9  1.2328555  0.6360261  0.5097475  0.6247009  0.2577766  0.5951461 #>   11  1.0782278  0.6340632  0.5203342  0.6095726  0.2262241  0.5750704 #>   13  0.6905751  0.6438209  0.5202541  0.6143590  0.2375240  0.5794117 #>   15  0.6884231  0.6386621  0.5269275  0.6119536  0.2314113  0.5749646 #>   17  0.6793789  0.6402778  0.5203508  0.6068254  0.2211182  0.5725103 #>   19  0.6735896  0.6417304  0.5173074  0.6117460  0.2347800  0.5645023 #>   21  0.6639009  0.6502480  0.5136864  0.6093407  0.2294590  0.5623978 #>   23  0.6628867  0.6429422  0.5271042  0.6024908  0.2168394  0.5522164 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.5541667    0.7047619    0.6948545       0.5858345       0.6948545 #>   0.5398810    0.7277778    0.7046693       0.5854978       0.7046693 #>   0.5315476    0.7293651    0.6987698       0.5804389       0.6987698 #>   0.5172619    0.7119048    0.6892593       0.5665308       0.6892593 #>   0.5172619    0.7238095    0.6871825       0.5720010       0.6871825 #>   0.5119048    0.7214286    0.6844048       0.5691414       0.6844048 #>   0.5166667    0.7055556    0.6712302       0.5682552       0.6712302 #>   0.4898810    0.7476190    0.6959524       0.5685281       0.6959524 #>   0.4851190    0.7468254    0.7012698       0.5632900       0.7012698 #>   0.4720238    0.7476190    0.7046429       0.5555568       0.7046429 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.5541667  0.2938706       0.6294643         #>   0.5398810  0.2867033       0.6338294         #>   0.5315476  0.2819414       0.6304563         #>   0.5172619  0.2748230       0.6145833         #>   0.5172619  0.2746398       0.6205357         #>   0.5119048  0.2722589       0.6166667         #>   0.5166667  0.2744811       0.6111111         #>   0.4898810  0.2603053       0.6187500         #>   0.4851190  0.2577411       0.6159722         #>   0.4720238  0.2507326       0.6098214         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was k = 7. #> k-Nearest Neighbors  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 127, 127, 127, 128, 127, 126, ...  #> Resampling results across tuning parameters: #>  #>   k  logLoss   AUC        prAUC      Accuracy   Kappa      F1        #>   5  2.117061  0.6671840  0.4985782  0.6319414  0.2684773  0.6033431 #>   6  1.214363  0.6505385  0.4905817  0.6425031  0.2893426  0.6199563 #>   7  1.146843  0.6472222  0.4918258  0.6181319  0.2426935  0.5871552 #>   8  1.160049  0.6324192  0.4919960  0.6131868  0.2341963  0.5837480 #>   9  1.159630  0.6238308  0.4998371  0.6082418  0.2230264  0.5791040 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.5517857    0.7214286    0.7167328       0.5934367       0.7167328 #>   0.5690476    0.7253968    0.7253836       0.5990717       0.7253836 #>   0.5297619    0.7166667    0.7049206       0.5769481       0.7049206 #>   0.5351190    0.7031746    0.6975998       0.5739165       0.6975998 #>   0.5291667    0.6984127    0.6915873       0.5684466       0.6915873 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.5517857  0.2940659       0.6366071         #>   0.5690476  0.3030891       0.6472222         #>   0.5297619  0.2820024       0.6232143         #>   0.5351190  0.2843834       0.6191468         #>   0.5291667  0.2819780       0.6137897         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was k = 6. # Plot class probabilities knn.ST_S$`Class Probabilities Plot` # ROC plot knn.ST_S$ROC_Plot # Variable importance knn.ST_S$VariableImportance # Model quality knn.ST_S$`Model quality` #> Confusion Matrix and Statistics #>  #>           Reference #> Prediction  R  S #>          R 20  8 #>          S 11 20 #>                                            #>                Accuracy : 0.678            #>                  95% CI : (0.5436, 0.7938) #>     No Information Rate : 0.5254           #>     P-Value [Acc > NIR] : 0.01262          #>                                            #>                   Kappa : 0.3576           #>                                            #>  Mcnemar's Test P-Value : 0.64636          #>                                            #>             Sensitivity : 0.6452           #>             Specificity : 0.7143           #>          Pos Pred Value : 0.7143           #>          Neg Pred Value : 0.6452           #>              Prevalence : 0.5254           #>          Detection Rate : 0.3390           #>    Detection Prevalence : 0.4746           #>       Balanced Accuracy : 0.6797           #>                                            #>        'Positive' Class : R                #>   # Training object knn.ST_S$Training #> k-Nearest Neighbors  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 127, 127, 127, 128, 127, 126, ...  #> Resampling results across tuning parameters: #>  #>   k  logLoss   AUC        prAUC      Accuracy   Kappa      F1        #>   5  2.117061  0.6671840  0.4985782  0.6319414  0.2684773  0.6033431 #>   6  1.214363  0.6505385  0.4905817  0.6425031  0.2893426  0.6199563 #>   7  1.146843  0.6472222  0.4918258  0.6181319  0.2426935  0.5871552 #>   8  1.160049  0.6324192  0.4919960  0.6131868  0.2341963  0.5837480 #>   9  1.159630  0.6238308  0.4998371  0.6082418  0.2230264  0.5791040 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.5517857    0.7214286    0.7167328       0.5934367       0.7167328 #>   0.5690476    0.7253968    0.7253836       0.5990717       0.7253836 #>   0.5297619    0.7166667    0.7049206       0.5769481       0.7049206 #>   0.5351190    0.7031746    0.6975998       0.5739165       0.6975998 #>   0.5291667    0.6984127    0.6915873       0.5684466       0.6915873 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.5517857  0.2940659       0.6366071         #>   0.5690476  0.3030891       0.6472222         #>   0.5297619  0.2820024       0.6232143         #>   0.5351190  0.2843834       0.6191468         #>   0.5291667  0.2819780       0.6137897         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was k = 6.  # Tuning object knn.ST_S$Tuning #> k-Nearest Neighbors  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 127, 128, 128, 127, 126, 126, ...  #> Resampling results across tuning parameters: #>  #>   k   logLoss    AUC        prAUC      Accuracy   Kappa      F1        #>    5  2.2616126  0.6500709  0.4828789  0.6260562  0.2572795  0.6009026 #>    7  1.4423420  0.6460530  0.5016384  0.6289377  0.2653482  0.5986522 #>    9  1.2328555  0.6360261  0.5097475  0.6247009  0.2577766  0.5951461 #>   11  1.0782278  0.6340632  0.5203342  0.6095726  0.2262241  0.5750704 #>   13  0.6905751  0.6438209  0.5202541  0.6143590  0.2375240  0.5794117 #>   15  0.6884231  0.6386621  0.5269275  0.6119536  0.2314113  0.5749646 #>   17  0.6793789  0.6402778  0.5203508  0.6068254  0.2211182  0.5725103 #>   19  0.6735896  0.6417304  0.5173074  0.6117460  0.2347800  0.5645023 #>   21  0.6639009  0.6502480  0.5136864  0.6093407  0.2294590  0.5623978 #>   23  0.6628867  0.6429422  0.5271042  0.6024908  0.2168394  0.5522164 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.5541667    0.7047619    0.6948545       0.5858345       0.6948545 #>   0.5398810    0.7277778    0.7046693       0.5854978       0.7046693 #>   0.5315476    0.7293651    0.6987698       0.5804389       0.6987698 #>   0.5172619    0.7119048    0.6892593       0.5665308       0.6892593 #>   0.5172619    0.7238095    0.6871825       0.5720010       0.6871825 #>   0.5119048    0.7214286    0.6844048       0.5691414       0.6844048 #>   0.5166667    0.7055556    0.6712302       0.5682552       0.6712302 #>   0.4898810    0.7476190    0.6959524       0.5685281       0.6959524 #>   0.4851190    0.7468254    0.7012698       0.5632900       0.7012698 #>   0.4720238    0.7476190    0.7046429       0.5555568       0.7046429 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.5541667  0.2938706       0.6294643         #>   0.5398810  0.2867033       0.6338294         #>   0.5315476  0.2819414       0.6304563         #>   0.5172619  0.2748230       0.6145833         #>   0.5172619  0.2746398       0.6205357         #>   0.5119048  0.2722589       0.6166667         #>   0.5166667  0.2744811       0.6111111         #>   0.4898810  0.2603053       0.6187500         #>   0.4851190  0.2577411       0.6159722         #>   0.4720238  0.2507326       0.6098214         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was k = 7. # You can also access the training and testing datasets from the resulted list knn.ST_S$`Training Data` knn.ST_S$`Test Data`"},{"path":"/articles/ML_Workflows.html","id":"binary-classification-imbalanced-data","dir":"Articles","previous_headings":"","what":"Binary classification: imbalanced data","title":"Predictive Modeling using tuneTrain()","text":"BarleyRNOWC dataset used illustrate binary classification imbalanced data, purpose modeling response classification barley Kernel row number type climate variables. response variable RNO categorizes barley following levels: 1 (Six-rowed): represents barley genotypes six distinct rows kernels spike. 2 (Two-rowed): represents barley genotypes two distinct rows kernels spike. 3 (Two-rowed - rudimentary florets): represents two-rowed barley underdeveloped rudimentary florets. 4 (Irregular lateral florets): represents barley genotypes irregularly developed lateral florets spike. 5 (Irregular: 2 6 rows): represents heterogeneous genotypes showing spikes two-rowed six-rowed characteristics. 10 (Heterogeneous): represents genetically diverse group mixed spike structures. example, use first 2 categories : six-rowed (cl_1) two-rowed (cl_2). Class Probabilities RNO using Random Forest Roc Plot RNO using Random Forest Variable Importance RNO using Random Forest","code":"# Load sample data data(BarleyRNOWC)  # Count classes for data imbalance check BarleyRNOWC %>%   count(RNO) #>   RNO   n #> 1   1 170 #> 2   2  30  ## Binary classification of RNO rf.RNO <- tuneTrain(data = BarleyRNOWC,                       y = 'RNO',                       method = 'rf',                       summary = multiClassSummary,                       imbalanceMethod = \"up\",                       imbalanceThreshold = 0.2,                       process = c(\"scale\", \"center\"),                       classProbs = TRUE,                       repeats = 3) #> Random Forest  #>  #> 140 samples #>  55 predictor #>   2 classes: 'Cl_1', 'Cl_2'  #>  #> Pre-processing: scaled (55), centered (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 126, 126, 126, 126, 126, 126, ...  #> Addtional sampling using up-sampling prior to pre-processing #>  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss   AUC        prAUC      Accuracy   Kappa      F1        #>    2    1.436070  0.7476852  0.4196864  0.7865690  0.3195494  0.8640164 #>    7    1.514558  0.7419613  0.4360995  0.7789255  0.2284394  0.8633581 #>   13    1.870873  0.7203914  0.4096570  0.7578144  0.1728108  0.8493871 #>   19    1.501019  0.7403830  0.4364434  0.7569475  0.2059739  0.8456626 #>   25    1.793648  0.7391414  0.4262912  0.7835043  0.2397354  0.8661214 #>   31    1.802653  0.7130051  0.4081247  0.7761783  0.2400216  0.8594466 #>   37    1.711508  0.7451599  0.4158203  0.7552503  0.1921877  0.8454244 #>   43    1.690353  0.7302189  0.4299397  0.7715995  0.2365599  0.8559213 #>   49    1.671412  0.7347222  0.4131576  0.7867521  0.2524940  0.8679252 #>   55    1.746767  0.7247896  0.4243801  0.7622589  0.1919837  0.8517818 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.8318182    0.5277778    0.9104511       0.4520525       0.9104511 #>   0.8401515    0.4388889    0.8968864       0.3402211       0.8968864 #>   0.8234848    0.3833333    0.8857779       0.3014778       0.8857779 #>   0.8116162    0.4500000    0.8972484       0.3188776       0.8972484 #>   0.8457071    0.4333333    0.8972749       0.3818878       0.8972749 #>   0.8313131    0.4555556    0.9020781       0.3687925       0.9020781 #>   0.8121212    0.4277778    0.8931469       0.3041667       0.8931469 #>   0.8229798    0.4722222    0.9050126       0.3539116       0.9050126 #>   0.8431818    0.4611111    0.9030042       0.3508730       0.9030042 #>   0.8204545    0.4277778    0.8957248       0.3015306       0.8957248 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.8318182  0.7076068       0.6797980         #>   0.8401515  0.7142491       0.6395202         #>   0.8234848  0.7002808       0.6034091         #>   0.8116162  0.6898901       0.6308081         #>   0.8457071  0.7190110       0.6395202         #>   0.8313131  0.7068987       0.6434343         #>   0.8121212  0.6907570       0.6199495         #>   0.8229798  0.6999389       0.6476010         #>   0.8431818  0.7173138       0.6521465         #>   0.8204545  0.6975824       0.6241162         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 49. #> Random Forest  #>  #> 140 samples #>  55 predictor #>   2 classes: 'Cl_1', 'Cl_2'  #>  #> Pre-processing: scaled (55), centered (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 126, 125, 126, 126, 126, 126, ...  #> Addtional sampling using up-sampling prior to pre-processing #>  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss   AUC        prAUC      Accuracy   Kappa      F1        #>   47    1.639892  0.7233375  0.4345348  0.7672894  0.2207960  0.8521266 #>   48    1.839672  0.7059764  0.4269922  0.7626862  0.2206060  0.8479758 #>   49    1.871368  0.7000842  0.4059849  0.7533455  0.2023018  0.8421738 #>   50    1.613479  0.7179082  0.4225698  0.7552259  0.2085086  0.8434495 #>   51    1.574021  0.7051136  0.4182123  0.7484005  0.2156166  0.8369782 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.8270202    0.4277778    0.8916624       0.3439153       0.8916624 #>   0.8184343    0.4444444    0.8910499       0.3232143       0.8910499 #>   0.8131313    0.4166667    0.8865795       0.3388889       0.8865795 #>   0.8128788    0.4333333    0.8900126       0.3142036       0.8900126 #>   0.7962121    0.4833333    0.8989118       0.3174320       0.8989118 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.8270202  0.7032723       0.6273990         #>   0.8184343  0.6961050       0.6314394         #>   0.8131313  0.6913675       0.6148990         #>   0.8128788  0.6908669       0.6231061         #>   0.7962121  0.6768987       0.6397727         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 47.  # same outputs of binary classification task names(rf.RNO) #> [1] \"Tuning\"                   \"Training\"                 #> [3] \"Model quality\"            \"VariableImportance\"       #> [5] \"ROC_Plot\"                 \"Class Probabilities\"      #> [7] \"Class Probabilities Plot\" \"Training Data\"            #> [9] \"Test Data\" ## Plot class probabilities rf.RNO$`Class Probabilities Plot` ## ROC plot rf.RNO$ROC_Plot ## Variable importance rf.RNO$VariableImportance"},{"path":"/articles/ML_Workflows.html","id":"regression","dir":"Articles","previous_headings":"","what":"Regression","title":"Predictive Modeling using tuneTrain()","text":"DurumWheatDHEWC dataset designed modeling climate impacts days heading (DHE) durum wheat. contains multiple columns representing climate variables, used predictors, numeric response variable, DHE, indicates number days required durum wheat reach heading stage. Variable Importance DHE Predicted vs Actual DHE Residuals vs predicted DHE","code":"# Load sample data for regression task data(\"DurumWheatDHEWC\")  ## Regression of DHE (days to heading) svm.DHE <- tuneTrain(data = DurumWheatDHEWC,                       y =  'DHE',                       method = 'svmLinear2',                       summary = defaultSummary,                       classProbs = FALSE,                       repeats = 3) #> Support Vector Machines with Linear Kernel  #>  #> 137 samples #>  55 predictor #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 124, 123, 123, 123, 124, 123, ...  #> Resampling results across tuning parameters: #>  #>   cost    RMSE      Rsquared   MAE      #>     0.25  4.392096  0.3874978  3.424457 #>     0.50  4.422735  0.3944809  3.404364 #>     1.00  4.471461  0.3923094  3.438605 #>     2.00  4.482016  0.3909093  3.431474 #>     4.00  4.629627  0.3641357  3.506504 #>     8.00  4.758136  0.3525155  3.548093 #>    16.00  4.962108  0.3316333  3.682896 #>    32.00  5.135696  0.3130516  3.818127 #>    64.00  5.209299  0.3139861  3.880438 #>   128.00  5.265016  0.3096848  3.924131 #>  #> RMSE was used to select the optimal model using the smallest value. #> The final value used for the model was cost = 0.25. #> Support Vector Machines with Linear Kernel  #>  #> 137 samples #>  55 predictor #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 123, 123, 124, 123, 123, 124, ...  #> Resampling results across tuning parameters: #>  #>   cost  RMSE      Rsquared   MAE      #>   0.25  4.374473  0.3888565  3.404007 #>   0.50  4.346750  0.4006997  3.346334 #>   0.75  4.348030  0.4065156  3.333252 #>   1.00  4.343706  0.4094038  3.314261 #>   1.25  4.350663  0.4096769  3.308364 #>  #> RMSE was used to select the optimal model using the smallest value. #> The final value used for the model was cost = 1.  # Regression outputs names(svm.DHE) #> [1] \"Tuning\"                       \"Training\"                     #> [3] \"Predictions\"                  \"Residuals Vs. Predicted Plot\" #> [5] \"Predicted vs Actual Plot\"     \"Quality_metrics\"              #> [7] \"VariableImportance\"           \"Training Data\"                #> [9] \"Test Data\" svm.DHE$VariableImportance svm.DHE$Quality_metrics #>      RMSE  Rsquared       MAE  #> 4.3359347 0.3971378 3.4593691 svm.DHE$`Predicted vs Actual Plot` svm.DHE$`Residuals Vs. Predicted Plot`"},{"path":"/articles/ML_Workflows.html","id":"multiclass-classification","dir":"Articles","previous_headings":"","what":"Multiclass classification","title":"Predictive Modeling using tuneTrain()","text":"case, use DurumWheatDHEWC dataset create days heading classes variable (DHE_Class) fit multiclass model. DHE_classes descibed follows: 1 (Early): Represents samples/observations early days heading, indicating adaptability shorter growing seasons favorable early-season conditions. 2 (Intermediate): Represents samples/observations moderate days heading, indicating typical average responses given environmental conditions. 3 (Late): Represents samples/observations late days heading, suggesting adaptability longer growing seasons late-season conditions.","code":"# Create DHE Classes from DurumWheatDHEWC dataset DurumWheatDHEWC$DHE_class <- ifelse(   DurumWheatDHEWC$DHE <= 172, \"1\",   ifelse(DurumWheatDHEWC$DHE <= 180, \"2\", \"3\")  )   # Convert to factor  DurumWheatDHEWC$DHE_class <- factor(DurumWheatDHEWC$DHE_class)     # Count classes for data imbalance check DurumWheatDHEWC %>%    count(DHE_class) #>   DHE_class  n #> 1         1 96 #> 2         2 87 #> 3         3 10 ## Run Multiclass Classification rf.DHE_class <- tuneTrain(data = DurumWheatDHEWC,                               y =  'DHE_class',                               method = 'rf',                               parallelComputing = TRUE,                               summary = multiClassSummary,                               imbalanceMethod =\"up\", # Here we upsample the less represented class (3)                               imbalanceThreshold = 0.2,                               classProbs = TRUE,                               repeats = 3) #> Random Forest  #>  #> 136 samples #>  56 predictor #>   3 classes: 'Cl_1', 'Cl_2', 'Cl_3'  #>  #> Pre-processing: centered (56), scaled (56)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 124, 122, 122, 123, 123, 122, ...  #> Addtional sampling using up-sampling prior to pre-processing #>  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss       AUC        prAUC       Accuracy   Kappa      Mean_F1   #>    2    0.5939983806  0.8747295  0.57783406  0.7183761  0.4776484  0.6151515 #>    8    0.3316253502  0.9771833  0.63240857  0.9121551  0.8351317  0.9521368 #>   14    0.2037479108  0.9997685  0.64667108  0.9508242  0.9074325  0.9871286 #>   20    0.1289448417  1.0000000  0.63822751  0.9805556  0.9641291  0.9909143 #>   26    0.0835792340  1.0000000  0.61626984  0.9976190  0.9957958  0.9975580 #>   32    0.0502943362  1.0000000  0.62063492  1.0000000  1.0000000  1.0000000 #>   38    0.0306568539  1.0000000  0.60740741  1.0000000  1.0000000  1.0000000 #>   44    0.0150253649  1.0000000  0.51441799  1.0000000  1.0000000  1.0000000 #>   50    0.0059382328  1.0000000  0.35661376  1.0000000  1.0000000  1.0000000 #>   56    0.0000245667  1.0000000  0.01111111  1.0000000  1.0000000  1.0000000 #>   Mean_Sensitivity  Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value #>   0.5215420         0.8302096         0.4950491            0.8493366           #>   0.7127740         0.9468254         0.9476190            0.9539387           #>   0.8435374         0.9700397         0.9890873            0.9783321           #>   0.9297052         0.9884259         0.9922969            0.9899534           #>   0.9977324         0.9986111         0.9977324            0.9980159           #>   1.0000000         1.0000000         1.0000000            1.0000000           #>   1.0000000         1.0000000         1.0000000            1.0000000           #>   1.0000000         1.0000000         1.0000000            1.0000000           #>   1.0000000         1.0000000         1.0000000            1.0000000           #>   1.0000000         1.0000000         1.0000000            1.0000000           #>   Mean_Precision  Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy #>   0.4809414       0.5215420    0.2394587            0.6750974              #>   0.9476190       0.7127740    0.3040517            0.8257748              #>   0.9890873       0.8435374    0.3169414            0.9066043              #>   0.9922969       0.9297052    0.3268519            0.9579082              #>   0.9977324       0.9977324    0.3325397            0.9978741              #>   1.0000000       1.0000000    0.3333333            1.0000000              #>   1.0000000       1.0000000    0.3333333            1.0000000              #>   1.0000000       1.0000000    0.3333333            1.0000000              #>   1.0000000       1.0000000    0.3333333            1.0000000              #>   1.0000000       1.0000000    0.3333333            1.0000000              #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 32. #> Random Forest  #>  #> 136 samples #>  56 predictor #>   3 classes: 'Cl_1', 'Cl_2', 'Cl_3'  #>  #> Pre-processing: centered (56), scaled (56)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 123, 122, 122, 122, 123, 123, ...  #> Addtional sampling using up-sampling prior to pre-processing #>  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss     AUC  prAUC      Accuracy  Kappa  Mean_F1  Mean_Sensitivity #>   30    0.06222947  1    0.6321429  1         1      1        1                #>   31    0.05730437  1    0.6276455  1         1      1        1                #>   32    0.05284178  1    0.6206349  1         1      1        1                #>   33    0.04716016  1    0.6152116  1         1      1        1                #>   34    0.04530740  1    0.6148148  1         1      1        1                #>   Mean_Specificity  Mean_Pos_Pred_Value  Mean_Neg_Pred_Value  Mean_Precision #>   1                 1                    1                    1              #>   1                 1                    1                    1              #>   1                 1                    1                    1              #>   1                 1                    1                    1              #>   1                 1                    1                    1              #>   Mean_Recall  Mean_Detection_Rate  Mean_Balanced_Accuracy #>   1            0.3333333            1                      #>   1            0.3333333            1                      #>   1            0.3333333            1                      #>   1            0.3333333            1                      #>   1            0.3333333            1                      #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 30. # List returned objects names(rf.DHE_class) #>  [1] \"Tuning\"             \"Training\"           \"Model quality\"      #>  [4] \"VariableImportance\" \"ROC_Results\"        \"AUC_Values\"         #>  [7] \"ROC_Plots\"          \"Probabilities_Plot\" \"Predictions\"        #> [10] \"Training Data\"      \"Test Data\" rf.DHE_class$`Model quality` #> Confusion Matrix and Statistics #>  #>           Reference #> Prediction Cl_1 Cl_2 Cl_3 #>       Cl_1   28    0    0 #>       Cl_2    0   26    1 #>       Cl_3    0    0    2 #>  #> Overall Statistics #>                                            #>                Accuracy : 0.9825           #>                  95% CI : (0.9061, 0.9996) #>     No Information Rate : 0.4912           #>     P-Value [Acc > NIR] : < 2.2e-16        #>                                            #>                   Kappa : 0.9676           #>                                            #>  Mcnemar's Test P-Value : NA               #>  #> Statistics by Class: #>  #>                      Class: Cl_1 Class: Cl_2 Class: Cl_3 #> Sensitivity               1.0000      1.0000     0.66667 #> Specificity               1.0000      0.9677     1.00000 #> Pos Pred Value            1.0000      0.9630     1.00000 #> Neg Pred Value            1.0000      1.0000     0.98182 #> Prevalence                0.4912      0.4561     0.05263 #> Detection Rate            0.4912      0.4561     0.03509 #> Detection Prevalence      0.4912      0.4737     0.03509 #> Balanced Accuracy         1.0000      0.9839     0.83333 rf.DHE_class$`Probabilities_Plot`"},{"path":"/articles/ML_Workflows.html","id":"splitdata","dir":"Articles","previous_headings":"","what":"splitData()","title":"Predictive Modeling using tuneTrain()","text":"","code":"# Subset septoriaDurumWC where column names having 3, ex tmin3, prec13 septoriaDurumWC_subset <- icardaFIGSr::septoriaDurumWC|>   dplyr::select(ST_S,contains(\"3\"))  # split data septoriaDurumWC_subset_split <- icardaFIGSr::splitData(septoriaDurumWC,                         seed = 123, y=\"ST_S\", p=0.7)  # Check results names(septoriaDurumWC_subset_split) #> [1] \"trainset\" \"testset\""},{"path":"/articles/ML_Workflows.html","id":"getmetrics","dir":"Articles","previous_headings":"","what":"getMetrics()","title":"Predictive Modeling using tuneTrain()","text":"","code":"# Call the ST_S knn model fitted in tunTrain function section  data.test <- knn.ST_S$`Test Data`  pred.ST_S <- predict(knn.ST_S$Tuning, newdata = data.test[ , -1])  metrics.knn.ST_S <- getMetrics(y = data.test$ST_S,                                        yhat = pred.ST_S, classtype = 2)  metrics.knn.ST_S #> $Metrics #>                            Metrics #> Accuracy                     0.695 #> 95% CI              (0.561, 0.808) #> No Information Rate          0.525 #> P-Value [Acc > NIR]    0.006076751 #> Kappa                         0.39 #> Sensitivity                  0.677 #> Specificity                  0.714 #>  #> $CM #>    R  S #> R 21  8 #> S 10 20"},{"path":"/articles/ML_Workflows.html","id":"getmetricspca","dir":"Articles","previous_headings":"","what":"getMetricsPCA()","title":"Predictive Modeling using tuneTrain()","text":"Please run code chunk test getMetricsPCA() model rutrned tuneTrain().","code":"## Run Binary classification of ST_S with balanced data using random forest rf.ST_S <- tuneTrain(                       data = as.data.frame(septoriaDurumWC),                       y =  'ST_S',                       method = 'rf', # using rf algorithm                       summary = multiClassSummary, # Important for classification tasks                         parallelComputing = T,                       repeats = 3,                       process = c(\"center\",\"scale\"),                       classProbs = TRUE) # Important for classification tasks #> Random Forest  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 127, 128, 128, 127, 126, 126, ...  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss    AUC        prAUC      Accuracy   Kappa      F1        #>    2    0.6412434  0.7158659  0.6148240  0.6476190  0.2930938  0.6404406 #>    7    0.6617294  0.7012684  0.6019866  0.6447375  0.2873131  0.6373479 #>   13    0.6639525  0.7006803  0.6040758  0.6453968  0.2886863  0.6405937 #>   19    0.6743218  0.7056264  0.6070292  0.6424908  0.2823068  0.6393278 #>   25    0.6788256  0.6908163  0.5961963  0.6380952  0.2726412  0.6402410 #>   31    0.6755614  0.7024235  0.6010913  0.6408181  0.2777908  0.6397664 #>   37    0.6820936  0.7067319  0.6068832  0.6379365  0.2719193  0.6367858 #>   43    0.6761347  0.7018778  0.6006108  0.6358730  0.2675543  0.6349970 #>   49    0.6776657  0.6980442  0.5995196  0.6357143  0.2674820  0.6345067 #>   55    0.6780806  0.7001134  0.6051131  0.6239438  0.2438346  0.6197583 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.6136905    0.6801587    0.7010354       0.6172354       0.7010354 #>   0.6089286    0.6793651    0.7017941       0.6108862       0.7017941 #>   0.6184524    0.6706349    0.6924820       0.6156013       0.6924820 #>   0.6178571    0.6650794    0.6880640       0.6130087       0.6880640 #>   0.6279762    0.6452381    0.6824291       0.6150325       0.6824291 #>   0.6226190    0.6555556    0.6857095       0.6138023       0.6857095 #>   0.6178571    0.6547619    0.6858418       0.6076515       0.6858418 #>   0.6178571    0.6500000    0.6805243       0.6070563       0.6805243 #>   0.6232143    0.6444444    0.6763576       0.6134259       0.6763576 #>   0.6005952    0.6436508    0.6724423       0.5963360       0.6724423 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.6136905  0.3268864       0.6469246         #>   0.6089286  0.3240049       0.6441468         #>   0.6184524  0.3289255       0.6445437         #>   0.6178571  0.3287424       0.6414683         #>   0.6279762  0.3337118       0.6366071         #>   0.6226190  0.3314896       0.6390873         #>   0.6178571  0.3289499       0.6363095         #>   0.6178571  0.3291087       0.6339286         #>   0.6232143  0.3316728       0.6338294         #>   0.6005952  0.3199023       0.6221230         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 2. #> Random Forest  #>  #> 141 samples #>  55 predictor #>   2 classes: 'R', 'S'  #>  #> Pre-processing: centered (55), scaled (55)  #> Resampling: Cross-Validated (10 fold, repeated 3 times)  #> Summary of sample sizes: 126, 127, 127, 127, 128, 127, ...  #> Resampling results across tuning parameters: #>  #>   mtry  logLoss    AUC        prAUC      Accuracy   Kappa      F1        #>   1     0.6293363  0.7274376  0.6138804  0.6601587  0.3225280  0.6571339 #>   2     0.6423611  0.7105867  0.5970603  0.6535165  0.3103013  0.6477069 #>   3     0.6505847  0.7126630  0.6043934  0.6383394  0.2807041  0.6262665 #>   4     0.6485721  0.7140590  0.6069122  0.6507937  0.3057462  0.6440842 #>   Sensitivity  Specificity  Pos_Pred_Value  Neg_Pred_Value  Precision #>   0.6464286    0.6777778    0.6981085       0.6516138       0.6981085 #>   0.6339286    0.6777778    0.6920899       0.6418651       0.6920899 #>   0.6095238    0.6730159    0.6716138       0.6218711       0.6716138 #>   0.6244048    0.6841270    0.6948677       0.6314153       0.6948677 #>   Recall     Detection_Rate  Balanced_Accuracy #>   0.6464286  0.3435409       0.6621032         #>   0.6339286  0.3365324       0.6558532         #>   0.6095238  0.3237607       0.6412698         #>   0.6244048  0.3314286       0.6542659         #>  #> Accuracy was used to select the optimal model using the largest value. #> The final value used for the model was mtry = 1.  # get test data from one of the model to be used for prediction data.test <- rf.ST_S$`Test Data`  # Obtain predictions from previously run models : knn.ST_S and rf.ST_S pred.knn.ST_S <- predict(knn.ST_S$Tuning, newdata = data.test[ , -1]) pred.rf.ST_S <- predict(rf.ST_S$Tuning, newdata = data.test[ , -1])  # Get metrics for your model using computed metrics.knn.ST_S metrics.knn.ST_S <- metrics.knn.ST_S metrics.rf.ST_S <- icardaFIGSr::getMetrics(y = data.test$ST_S,                          yhat = pred.rf.ST_S, classtype = 2)  # Indexing for 2-class models to remove extra column with # names of performance measures metrics.all <- cbind(metrics.knn.ST_S, metrics.rf.ST_S)    ## check data structure metrics.all #>         metrics.knn.ST_S metrics.rf.ST_S #> Metrics data.frame,1     data.frame,1    #> CM      data.frame,2     data.frame,2 metrics.all[1,1] #> [[1]] #>                            Metrics #> Accuracy                     0.695 #> 95% CI              (0.561, 0.808) #> No Information Rate          0.525 #> P-Value [Acc > NIR]    0.006076751 #> Kappa                         0.39 #> Sensitivity                  0.677 #> Specificity                  0.714 metrics.all[2,1] #> [[1]] #>    R  S #> R 21  8 #> S 10 20"},{"path":"/articles/ML_Workflows.html","id":"make_prediction","dir":"Articles","previous_headings":"","what":"make_prediction()","title":"Predictive Modeling using tuneTrain()","text":"make_prediction() returns predictions classes probabilities corresponding plots.","code":"# Make prediction for septoriaDurumWC using the previous tuning model knn.ST_S$Tuning  data(\"septoriaDurumWC\")  septoriaDurumWC <- as.data.frame(septoriaDurumWC)  knn.pred <- make_prediction(newdata = septoriaDurumWC,                                       y='ST_S',                                       model = knn.ST_S$Tuning,                                       positive = \"R\",                                       auc = TRUE)  names(knn.pred) #> [1] \"ClassProbabilities\"     \"ClassProbabilitiesPlot\" \"ROC_Curves\"             #> [4] \"AUC\""},{"path":"/articles/Sites_climate.html","id":"getdaily","dir":"Articles","previous_headings":"","what":"getDaily()","title":"Extracting Sites Climate Data","text":"getDaily() retrieves daily climate Data ICARDA Genebank database given vector site_codes vector climate variables among possible choices. example demonstrates use function retrieve average daily temperature (tavg) subset sites.","code":"library(icardaFIGSr) # Extract daily data for durum wheat durum <- getAccessions(crop = 'Durum wheat', coor = TRUE) daily <- getDaily(sites = levels(as.factor(durum$SiteCode)),                      var = c('tavg', 'prec', 'rh'), cv = TRUE)"},{"path":"/articles/Sites_climate.html","id":"extractwcdata","dir":"Articles","previous_headings":"","what":"extractWcdata()","title":"Extracting Sites Climate Data","text":"extractWCdata() extracts monthly historical climate data WorldClim v2.1 specified climate variable(s) sites.","code":"library(icardaFIGSr)  # Get barley accessions barley_accs <- getAccessions(crop = \"Barley\", coor = TRUE)  barley_accs_bio <- extractWCdata(barley_accs, long = 'Longitude', lat = 'Latitude',                                    var = 'bio', res = 2.5)"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Zakaria Kehel. Author, maintainer. Chafik Analy. Author, contributor. Khadija Aouzal. Author. Khadija Aziz. Author. Bancy Ngatia. Author. Zainab Azough. Contributor. Amal Ibnelhobyb. Contributor. Fawzy Nawar. Contributor.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Kehel Z, Analy C, Aouzal K, Aziz K, Ngatia B (2025). icardaFIGSr: Subsetting using Focused Identification Germplasm Strategy (FIGS). R package version 1.0.2.","code":"@Manual{,   title = {icardaFIGSr: Subsetting using Focused Identification of the Germplasm Strategy (FIGS)},   author = {Zakaria Kehel and Chafik Analy and Khadija Aouzal and Khadija Aziz and Bancy Ngatia},   year = {2025},   note = {R package version 1.0.2}, }"},{"path":[]},{"path":"/index.html","id":"overview","dir":"","previous_headings":"","what":"Overview","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"icardaFIGSr package provides tools applying Focused Identification Germplasm Strategy (FIGS) plant genetic resources data. FIGS, users can subset collections efficiently identify promising accessions based traits, environmental data, statistical workflows. package designed support researchers genebank managers identification targeted germplasm subsets plant breeding, research & developpement, conservation purposes.","code":""},{"path":"/index.html","id":"features","dir":"","previous_headings":"","what":"Features","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"Access preprocess genebank environmental datasets. Handle climatic data crop-specific parameters effectively. Train machine learning models flexible workflows classification regression. Generate variable importance metrics predictions. Evaluate model performance using tools like ROC curves confusion matrices. Access preloaded datasets DurumWheatDHEWC, BarleyRNOWC, FIGS subsets, among others.","code":""},{"path":"/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"Install latest release CRAN: , install development version GitHub:","code":"install.packages(\"icardaFIGSr\") devtools::install_github(\"icarda/icardaFIGSr\")"},{"path":[]},{"path":"/index.html","id":"load-the-package","dir":"","previous_headings":"Getting Started","what":"Load the Package","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"","code":"library(icardaFIGSr)"},{"path":[]},{"path":"/index.html","id":"id_1-load-a-built-in-dataset","dir":"","previous_headings":"Getting Started > Example Workflow","what":"1. Load a Built-in Dataset","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"","code":"data(\"DurumWheatDHEWC\") head(DurumWheatDHEWC)"},{"path":"/index.html","id":"id_2-model-training-and-variable-importance","dir":"","previous_headings":"Getting Started > Example Workflow","what":"2. Model Training and Variable Importance","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"","code":"# Train a regression model on the loaded dataset model <- tuneTrain(data = DurumWheatDHEWC, y = 'DHE', method = 'rf', summary = defaultSummary, classProbs = FALSE)  # Evaluate variable importance var_imp <- varimpPred(newdata = model$`Test Data`, y = 'DHE', model = model$Training) var_imp$VariableImportancePlot"},{"path":"/index.html","id":"id_3-extract-onset-data","dir":"","previous_headings":"Getting Started > Example Workflow","what":"3. Extract Onset Data","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"","code":"# Extract onset and climatic data for durum wheat durum <- getAccessions(crop = 'Durum wheat', coor = FALSE) onset_data <- getOnset(sites = unique(durum$SiteCode), crop = 'ICDW',                 var = c('tavg', 'prec'), cv = TRUE) # Climate data head(onset_data[[1]])  # Onset and phenological data head(onset_data[[2]])"},{"path":"/index.html","id":"id_4-visualize-spatial-data","dir":"","previous_headings":"Getting Started > Example Workflow","what":"4. Visualize Spatial Data","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"","code":"# Map accessions by population type mapAccessions(df = durum, long = \"Longitude\", lat = \"Latitude\", y = \"PopulationType\")"},{"path":"/index.html","id":"vignettes","dir":"","previous_headings":"","what":"Vignettes","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"details examples available vignettes: Accessing Crop-Related Data: vignette(\"CropData\") Predictive Modeling using tuneTrain(): vignette(ML_Workflows) Extracting Sites Climate Data: vignette(Sites_climate) view vignettes locally:","code":"browseVignettes(\"icardaFIGSr\")"},{"path":"/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"package developed contributions : Zakaria Kehel (Maintainer Author) Chafik Analy (Author) Khadija Aouzal (Author) Khadija Aziz (Author) Bancy Ngatia (Author) Zainab Azough, Amal Ibnelhobyb, Fawzy Nawar (Contributors)","code":""},{"path":"/index.html","id":"contact","dir":"","previous_headings":"","what":"Contact","title":"Subsetting using Focused Identification of the Germplasm Strategy (FIGS)","text":"questions, please contact : Khadija Aouzal k.aouzal@cgiar.org Zakaria Kehel z.kehel@cgiar.org","code":""},{"path":"/reference/BarleyRNOWC.html","id":null,"dir":"Reference","previous_headings":"","what":"BarleyRNOWC — BarleyRNOWC","title":"BarleyRNOWC — BarleyRNOWC","text":"200 samples kernel row number observations barley collection 55 corresponding worldclim data.","code":""},{"path":"/reference/BarleyRNOWC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"BarleyRNOWC — BarleyRNOWC","text":"","code":"data(\"BarleyRNOWC\")"},{"path":"/reference/BarleyRNOWC.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"BarleyRNOWC — BarleyRNOWC","text":"details climate data can found worldclim","code":""},{"path":"/reference/BarleyRNOWC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"BarleyRNOWC — BarleyRNOWC","text":"","code":"if(interactive()){  # Load barley Kernel Row Number data with world climatic variables obtained from WorldClim database  data(\"BarleyRNOWC\")  }"},{"path":"/reference/durumDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"durumDaily — durumDaily","title":"durumDaily — durumDaily","text":"200 sites durum wheat collection daily climatic data.","code":""},{"path":"/reference/durumDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"durumDaily — durumDaily","text":"","code":"data(\"durumDaily\")"},{"path":"/reference/durumDaily.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"durumDaily — durumDaily","text":"data includes site unique identifier daily data 4 climatic variables (tmin, tmax, precipitation relative humidity)","code":""},{"path":"/reference/durumDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"durumDaily — durumDaily","text":"","code":"if(interactive()){  # Load durum wheat data with their daily climatic variables obtained from ICARDA database  data(\"durumDaily\") }"},{"path":"/reference/durumWC.html","id":null,"dir":"Reference","previous_headings":"","what":"durumWC — durumWC","title":"durumWC — durumWC","text":"200 sites durum wheat collection world clim data.","code":""},{"path":"/reference/durumWC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"durumWC — durumWC","text":"","code":"data(\"durumWC\")"},{"path":"/reference/durumWC.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"durumWC — durumWC","text":"data includes site unique identifier, longitude, latitude 55 worldclim data worldclim","code":""},{"path":"/reference/durumWC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"durumWC — durumWC","text":"","code":"if(interactive()){  # Load durum wheat data with world climatic variables obtained from WorldClim database  data(\"durumWC\")  }"},{"path":"/reference/DurumWheatDHEWC.html","id":null,"dir":"Reference","previous_headings":"","what":"DurumWheatDHEWC — DurumWheatDHEWC","title":"DurumWheatDHEWC — DurumWheatDHEWC","text":"193 samples Days heading durum wheat collection 55 worldclim data.","code":""},{"path":"/reference/DurumWheatDHEWC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"DurumWheatDHEWC — DurumWheatDHEWC","text":"","code":"data(\"DurumWheatDHEWC\")"},{"path":"/reference/DurumWheatDHEWC.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"DurumWheatDHEWC — DurumWheatDHEWC","text":"details climate data can found worldclim","code":""},{"path":"/reference/DurumWheatDHEWC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"DurumWheatDHEWC — DurumWheatDHEWC","text":"","code":"if(interactive()){  # Load durum wheat Days to Heading data with world climatic variables obtained from WorldClim database  data(\"DurumWheatDHEWC\")  }"},{"path":"/reference/extractWCdata.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"extractWCdata returns data frame based specified climatic variables. function modifies getData function raster R package extract world climate data version 2.1 instead version 1.4.","code":""},{"path":"/reference/extractWCdata.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"","code":"extractWCdata(sites, long, lat, var, res = 2.5)"},{"path":"/reference/extractWCdata.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"sites object class \"data.frame\" coordinates sites extract data. long character. Name column sites longitude. lat character. Name column sites latitude. var character. Climatic variable(s) extracted: 'tavg', 'tmin', 'tmax', 'prec', 'bio', 'srad', 'vapr', 'wind'. res numeric. Spatial resolution. Default 2.5.","code":""},{"path":"/reference/extractWCdata.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"object class \"data.frame\" specified climatic variables coordinates sites.","code":""},{"path":"/reference/extractWCdata.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"grid can created particular coordinates used input sites (see section 'Examples'). extractWCdata use given coordinates extract data WorldClim 2.1 database. extracted data likely contain NAs sites climate data available. removed imputed using data make predictions.","code":""},{"path":"/reference/extractWCdata.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"Zakaria Kehel, Fawzy Nawar, Bancy Ngatia, Khadija Aouzal, Chafik Analy","code":""},{"path":"/reference/extractWCdata.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracting historical climate data from WorldClim 2.1 — extractWCdata","text":"","code":"if (FALSE) { # \\dontrun{  # Create grid  long <- seq(-16, 115, length = 3)  lat <- seq(25, 59, length = 3)  sf <- expand.grid(x = sp1, y = sp2)   # Extract data using grid  sp.df0 <- extractWCdata(sf, long = 'long', lat = 'lat', var = 'bio')  sp.df <- na.omit(sp.df0)  } # }"},{"path":"/reference/FIGS.html","id":null,"dir":"Reference","previous_headings":"","what":"FIGS — FIGS","title":"FIGS — FIGS","text":"FIGS subset wheat sodicity resistance constructed using FAO harmonized world soil database HWSD","code":""},{"path":"/reference/FIGS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"FIGS — FIGS","text":"","code":"data(\"FIGS\")"},{"path":"/reference/FIGS.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"FIGS — FIGS","text":"data frame 201 rows 15 variables","code":""},{"path":"/reference/FIGS.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"FIGS — FIGS","text":"HWSD","code":""},{"path":"/reference/FIGS.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"FIGS — FIGS","text":"","code":"if(interactive()){  data(\"FIGS\") }"},{"path":"/reference/getAccessions.html","id":null,"dir":"Reference","previous_headings":"","what":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"Return data frame accession data specified crop specified list accession numbers (.e. IGs).","code":""},{"path":"/reference/getAccessions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"","code":"getAccessions(   crop = \"\",   ori = NULL,   IG = \"\",   doi = FALSE,   taxon = FALSE,   collectionYear = FALSE,   coor = FALSE,   available = FALSE,   other_id = FALSE )"},{"path":"/reference/getAccessions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"crop character. Crop get accession data. See section 'Details' available crops use getCrops function. Default: \"\". ori string. Country origin using ISO 3166-1 alpha-3 country codes. Default: NULL. IG integer. List accession numbers. Default: \"\". doi boolean. TRUE , function return digital object identifiers DOI accessions. Default: FALSE. taxon boolean. TRUE, function return taxon information accessions. Default: FALSE. collectionYear boolean. TRUE, function return year collecting mission. Default: FALSE. coor boolean. TRUE, returns georeferenced accessions. Default: FALSE. available boolean. TRUE, returns available accessions distribution, Default: FALSE.","code":""},{"path":"/reference/getAccessions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"data frame accession passport data specified crop crop locations ori specified.","code":""},{"path":"/reference/getAccessions.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"list available crops can fetched ICARDA's Genebank database using getCrops.","code":""},{"path":"/reference/getAccessions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"Khadija Aouzal, Amal Ibnelhobyb, Zakaria Kehel, Fawzy Nawar","code":""},{"path":"/reference/getAccessions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Getting Accession Data from ICARDA's Genebank Database. — getAccessions","text":"","code":"if (FALSE) { # \\dontrun{  # Obtain accession data for durum wheat  durum <- getAccessions(crop = 'Durum wheat', coor = TRUE)  } # }"},{"path":"/reference/getCrops.html","id":null,"dir":"Reference","previous_headings":"","what":"Crops Available in ICARDA's Genebank — getCrops","title":"Crops Available in ICARDA's Genebank — getCrops","text":"function allows obtain list crops available ICARDA's Genebank Database, returns list codes names available crops.","code":""},{"path":"/reference/getCrops.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Crops Available in ICARDA's Genebank — getCrops","text":"","code":"getCrops()"},{"path":"/reference/getCrops.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Crops Available in ICARDA's Genebank — getCrops","text":"list containing crops available ICARDA's Genebank Documentation System.","code":""},{"path":"/reference/getCrops.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Crops Available in ICARDA's Genebank — getCrops","text":"crop codes names fetched ICARDA's Genebank database.","code":""},{"path":"/reference/getCrops.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Crops Available in ICARDA's Genebank — getCrops","text":"Zakaria Kehel, Fawzy Nawar","code":""},{"path":"/reference/getCrops.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Crops Available in ICARDA's Genebank — getCrops","text":"","code":"if (FALSE) { # \\dontrun{  # Get list of available crops  crops <- getCrops()  } # }"},{"path":"/reference/getCropTraits.html","id":null,"dir":"Reference","previous_headings":"","what":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"Return data frame containing traits associated particular crop, description related identifiers.","code":""},{"path":"/reference/getCropTraits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"","code":"getCropTraits(crop)"},{"path":"/reference/getCropTraits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"crop character. Crop get available traits.","code":""},{"path":"/reference/getCropTraits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"data frame traits associated crop specified crop.","code":""},{"path":"/reference/getCropTraits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"getCropTraits returns data frame traits together IDs coding system used trait. Possible inputs crop include: 'ICAG' Aegilops 'ICB' Barley 'ICBW' Bread wheat 'ILC' Chickpea 'ICDW' Durum wheat 'ILB' Faba bean 'BPL' Faba bean BPL 'IFMI' Forage range 'IFLA' Lathyrus 'ILL' Lentil 'IFMA' Medicago annual 'IC' mandate cereals 'IFPI' Pisum 'ICPW' Primitive wheat 'IFTR' Trifolium 'IFVI' Vicia 'ICWH' Wheat hybrids 'ICWW' Wheat wild relatives 'ILWC' Wild Cicer 'ICWB' Wild Hordeum 'ILWL' Wild Lens 'ICWT' Wild Triticum list available crops use input crop can also obtained ICARDA's online server using getCrops.","code":""},{"path":"/reference/getCropTraits.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"Khadija Aouzal, Amal Ibnelhobyb, Zakaria Kehel, Fawzy Nawar, Chafik Analy","code":""},{"path":"/reference/getCropTraits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Documentation System — getCropTraits","text":"","code":"if (FALSE) { # \\dontrun{  # Get traits for bread wheat  breadTraits <- getCropTraits(crop = 'Bread wheat') } # }"},{"path":"/reference/getDaily.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting Daily Climatic Variables — getDaily","title":"Extracting Daily Climatic Variables — getDaily","text":"function extracts daily values climatic variables ICARDA Data, returns list data frame based specified climatic variables. variable 365 values day calendar year.","code":""},{"path":"/reference/getDaily.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting Daily Climatic Variables — getDaily","text":"","code":"getDaily(sites, var, cv = FALSE)"},{"path":"/reference/getDaily.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting Daily Climatic Variables — getDaily","text":"sites character. Names sites extract data. var character. Climatic variable(s) extracted. cv boolean. TRUE, returns data frame coefficient variation variable day calendar year. Default: FALSE.","code":""},{"path":"/reference/getDaily.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting Daily Climatic Variables — getDaily","text":"object specified climatic variables specified site code sites. cv = TRUE, object list containing two data frames: first one average daily values climatic variables, second one daily coefficient variation climatic variable. cv = FALSE, object data frame average daily values climatic variables.","code":""},{"path":"/reference/getDaily.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracting Daily Climatic Variables — getDaily","text":"getDaily extract daily climatic variables specified var sites specified sites online repository. .         function extracts average daily values starting first day calendar year, last day calendar year. Thus, returning 365 columns daily values created variable.","code":""},{"path":[]},{"path":"/reference/getDaily.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracting Daily Climatic Variables — getDaily","text":"Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/getDaily.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracting Daily Climatic Variables — getDaily","text":"","code":"if (FALSE) { # \\dontrun{  # Extract daily data for durum wheat  durum <- getAccessions(crop = 'Durum wheat', coor = TRUE)  daily <- getDaily(sites = levels(as.factor(durum$SiteCode)),                    var = c('tavg', 'prec', 'rh'), cv = TRUE)   # Get data frame with coefficient of variation from list object  # returned (when cv = TRUE)  daily.cv <- daily[[2]]  } # }"},{"path":"/reference/getGrowthPeriod.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"Calculates growing degree days (GDD) well cumulative GDD, returns list various data frames based specified arguments.","code":""},{"path":"/reference/getGrowthPeriod.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"","code":"getGrowthPeriod(sitecode, crop, base, max, gdd = FALSE)"},{"path":"/reference/getGrowthPeriod.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"sitecode expression. Vector names sites extract onset data. crop character. Crop name, calculations available 'Barley', 'Bread wheat', 'Chickpea', 'Durum wheat' 'Lentil'. base integer. Minimum temperature constraint crop. max integer. Maximum temperature constraint crop. gdd boolean. TRUE, returns data frame containing calculated GDD accumulated GDD together climatic variables used calculations. Default: FALSE.","code":""},{"path":"/reference/getGrowthPeriod.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"list object different data frames depending specified option gdd. gdd = TRUE, object list containing three data frames: first one lengths different growing stages, second one original onset data phenological variables, third one calculated GDD accumulated GDD sites specified sitecode. gdd = FALSE, object list containing two data frames: first one lengths different growing stages, second one original onset data phenological variables sites specified sitecode.","code":""},{"path":"/reference/getGrowthPeriod.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"Growing degree days various crops calculated using average daily minimum maximum temperature values obtained onset data. temperature constraints specified base max first applied calculations done. constraints ensure low high temperatures prevent growth particular crop included. Crops GDD calculations available include: 'Barley', 'Bread wheat', 'Chickpea', 'Durum wheat' 'Lentil'. can supplied options argument crop. Cumulative GDD values determine length different growing stages. Growing stages vary depending type crop. Durum wheat, bread wheat barley five growth stages, .e. beginning heading, beginning completion flowering, beginning completion grain filling. Chickpea lentil four growth stages, .e. beginning flowering, completion 50% flowering, beginning seed filling, completion 90% maturity (chickpea) full maturity (lentil). length full growth cycle crop site also given output data frame.","code":""},{"path":"/reference/getGrowthPeriod.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"Chafik Analy, Khadija Aouzal, Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/getGrowthPeriod.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculating Growing Degree Days and Lengths of Growth Stages for Various Crops Using Onset Data from ICARDA's Genebank Database — getGrowthPeriod","text":"","code":"if (FALSE) { # \\dontrun{  # Calculate GDD for durum wheat  data(durumDaily)    growth <- getGrowthPeriod(sitecode = levels(as.factor(durumDaily$site_code)),                            crop = 'Durum wheat', base = 0,                            max = 35, gdd = TRUE)   # Get the dataframe with lengths of growth stages from the returned list  growth.lengths <- growth[[1]]   # Get the dataframe with phenological variables from the returned list  growth.pheno <- growth[[2]]   # Get the dataframe with GDD, cumulative GDD, tmin and tmax from the returned list (when gdd = TRUE)  growth.gdd <- growth[[3]]  } # }"},{"path":"/reference/getMetrics.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance Measures for classification tasks — getMetrics","title":"Performance Measures for classification tasks — getMetrics","text":"function allows obtain performance measures Confusion Matrix, returns data frame containing performance measures confusion matrix given caret package.","code":""},{"path":"/reference/getMetrics.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance Measures for classification tasks — getMetrics","text":"","code":"getMetrics(y, yhat, classtype)"},{"path":"/reference/getMetrics.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance Measures for classification tasks — getMetrics","text":"y expression. class variable. yhat expression. vector predicted values. classtype character numeric. number levels y.","code":""},{"path":"/reference/getMetrics.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance Measures for classification tasks — getMetrics","text":"Outputs object performance measures calculated confusion matrix given caret package. data frame resulting output first column giving name performance measure, second column giving corresponding value.","code":""},{"path":"/reference/getMetrics.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance Measures for classification tasks — getMetrics","text":"getMetrics works target variables two, three, four, six eight classes. function relies caret package obtain confusion matrix performance measures extracted. can run several algorithms, results combined one data frame easier comparison (see section 'Examples'). Predictions obtained beforehand used input yhat. predict.train function caret run without argument type obtaining predictions.","code":""},{"path":[]},{"path":"/reference/getMetrics.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Performance Measures for classification tasks — getMetrics","text":"Zakaria Kehel, Bancy Ngatia, Khadija Aziz, Chafik Analy","code":""},{"path":"/reference/getMetrics.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance Measures for classification tasks — getMetrics","text":"","code":"if (FALSE) { # \\dontrun{ # Obtain predictions from previous models   data(septoriaDurumWC)   split.data <- splitData(septoriaDurumWC, seed = 1234, y = \"ST_S\", p = 0.7) data.train <- split.data$trainset data.test <- split.data$testset  knn.mod <- tuneTrain(data = septoriaDurumWC,y = 'ST_S',method = 'knn',positive = 'R') nnet.mod <- tuneTrain(data = septoriaDurumWC,y = 'ST_S',method = 'nnet',positive = 'R')   pred.knn <- predict(knn.mod$Model, newdata = data.test[ , -1]) pred.nnet <- predict(nnet.mod$Model, newdata = data.test[ , -1])  metrics.knn <- getMetrics(y = data.test$ST_S, yhat = pred.knn, classtype = 2) metrics.nnet <- getMetrics(y = data.test$ST_S, yhat = pred.nnet, classtype = 2) } # }"},{"path":"/reference/getMetricsPCA.html","id":null,"dir":"Reference","previous_headings":"","what":"Performance Measures with PCA pre-processing — getMetricsPCA","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"getMetricsPCA allows obtain performance measures Confusion Matrix algorithms PCA pre-processing,returns data frame containing performance measures confusion matrix given caret package algorithms run PCA pre-processing.","code":""},{"path":"/reference/getMetricsPCA.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"","code":"getMetricsPCA(yhat, y, classtype, model)"},{"path":"/reference/getMetricsPCA.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"yhat expression. vector predicted values. y expression. class variable. classtype character numeric. number levels y. model expression. model object output model assigned.","code":""},{"path":"/reference/getMetricsPCA.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"Outputs object performance measures calculated confusion matrix given caret package. data frame resulting output first column giving name performance measure, second column giving corresponding value.","code":""},{"path":"/reference/getMetricsPCA.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"Works target variables two, three, four, six eight classes. Similar getMetrics used case models run PCA specified option preProcess argument train function caret.","code":""},{"path":[]},{"path":"/reference/getMetricsPCA.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"Khadija Aziz, Zainab Azough, Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/getMetricsPCA.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Performance Measures with PCA pre-processing — getMetricsPCA","text":"","code":"if (FALSE) { # \\dontrun{  # Obtain predictions from several previously run models  dataX <- subset(data, select = -y)  pred.knn <- predict(model.knn, newdata = dataX)  pred.rf <- predict(model.rf, newdata = dataX)   # Get metrics for several algorithms  metrics.knn <- getMetricsPCA(y = data$y, yhat = pred.knn,                               classtype = 2, model = model.knn)  metrics.rf <- getMetricsPCA(y = data$y, yhat = pred.rf,                              classtype = 2, model = model.rf)   # Indexing for 2-class models to remove extra column with  # names of performance measures  metrics.all <- cbind(metrics.knn, metrics.rf[ , 2])   # No indexing needed for 3-, 4-, 6- or 8-class models  metrics.all <- cbind(metrics.knn, metrics.rf)  } # }"},{"path":"/reference/getOnset.html","id":null,"dir":"Reference","previous_headings":"","what":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"function extracts daily values climatic variables remote ICARDA data based Onset Planting, returns list based specified climatic variables. variable 365 values day (onset) year beginning planting day.","code":""},{"path":"/reference/getOnset.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"","code":"getOnset(sites, crop, var, cv = FALSE)"},{"path":"/reference/getOnset.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"sites character. Names sites extract data. crop character. Crop code ICARDA Genebank database. See section 'Details' list crops. var character. Climatic variable(s) extracted. choices : tavg, prec, rh cv boolean. TRUE, returns data frame coefficient variation variable day onset year. Default: FALSE.","code":""},{"path":"/reference/getOnset.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"cv = TRUE, returns list containing three data frames: first one average daily values climatic variables,second one phenological variables number day calendar year occurs sites specified sites, third one daily coefficient variation climatic variable. cv = FALSE, returns list containing two data frames: first one average daily values climatic variables, second one phenological variables number day calendar year occurs sites specified sites.","code":""},{"path":"/reference/getOnset.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"Similar getDaily except extracted data based 365 days starting onset planting. list available crops can fetched ICARDA Genebank database using getCrops.","code":""},{"path":[]},{"path":"/reference/getOnset.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"Khadija Aouzal, Amal Ibnelhobyb, Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/getOnset.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extracting Daily Climatic Variables Based on Onset of Planting — getOnset","text":"","code":"if (FALSE) { # \\dontrun{  # Extract onset data for durum wheat  durum <- getAccessions(crop = 'Durum wheat', coor = FALSE)  onset <- getOnset(sites = unique(durum$SiteCode), crop = 'ICDW',                    var = c('tavg', 'prec'), cv = TRUE)   # Get data frame with climatic variables from list object returned  onset.clim <- onset[[1]]   # Get data frame with coefficient of variation from list object  # returned (when cv = TRUE)  onset.cv <- onset[[2]]   # Get data frame with phenological variables from list object returned  onset.pheno <- onset[[3]]  } # }"},{"path":"/reference/getTraits.html","id":null,"dir":"Reference","previous_headings":"","what":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"Return data frame containing traits associated particular crop, description related identifiers.","code":""},{"path":"/reference/getTraits.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"","code":"getTraits(crop)"},{"path":"/reference/getTraits.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"crop character. Crop get available traits.","code":""},{"path":"/reference/getTraits.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"data frame traits associated crop specified crop.","code":""},{"path":"/reference/getTraits.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"getTraits returns data frame traits together IDs descriptions. list available crops use input crop can fetched ICARDA's Genebank database using getCrops.","code":""},{"path":"/reference/getTraits.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"Khadija Aouzal, Amal Ibnelhobyb, Zakaria Kehel, Fawzy Nawar","code":""},{"path":"/reference/getTraits.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Getting Traits Associated with Crops from the ICARDA's Genebank Database — getTraits","text":"","code":"if (FALSE) { # \\dontrun{ if(interactive()){  # Get traits for bread wheat  breadTraits <- getTraits(crop = 'Bread wheat')  } } # }"},{"path":"/reference/getTraitsData.html","id":null,"dir":"Reference","previous_headings":"","what":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"Return data frame observed values accessions associated Trait","code":""},{"path":"/reference/getTraitsData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"","code":"getTraitsData(IG, traitID)"},{"path":"/reference/getTraitsData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"IG factor. Unique identifier accession. traitID integer. Unique identifier trait (getTraits).","code":""},{"path":"/reference/getTraitsData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"data frame scores trait specified traitID accessions given IG.","code":""},{"path":"/reference/getTraitsData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"Possible inputs traitID can found using getTraits function (see section 'Examples').","code":""},{"path":"/reference/getTraitsData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"Khadija Aouzal, Amal Ibnelhobyb, Zakaria Kehel, Fawzy Nawar","code":""},{"path":"/reference/getTraitsData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Getting Trait Values of Accessions for a Specific Trait — getTraitsData","text":"","code":"if (FALSE) { # \\dontrun{ if(interactive()){  # Check trait ID for septoria and get septoria data for durum wheat  durum <- getAccessions(crop = 'Durum wheat', coor = TRUE)  durumTraits <- getTraits(crop = 'Durum wheat')  septoria <- getTraitsData(IG = durum$IG, traitID = 145)  } } # }"},{"path":"/reference/make_prediction.html","id":null,"dir":"Reference","previous_headings":"","what":"Make Predictions — make_prediction","title":"Make Predictions — make_prediction","text":"make_prediction makes predictions. returns list containing data frame predictions class probabilities, corresponding plots.","code":""},{"path":"/reference/make_prediction.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Make Predictions — make_prediction","text":"","code":"make_prediction(newdata, y, positive = NULL, model, scale = FALSE, auc = FALSE)"},{"path":"/reference/make_prediction.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Make Predictions — make_prediction","text":"newdata data frame. test dataset. y character string. name target variable. positive character string. positive class target variable y factor. Default: NULL. model model object. trained model returned caret::train. scale logical value. TRUE, scales variable importance values 0-100. Default: FALSE. auc logical value. TRUE, calculates area ROC curve (AUC) classification models. Default: FALSE.","code":""},{"path":"/reference/make_prediction.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Make Predictions — make_prediction","text":"list containing predictions, class probabilities, corresponding plots. classification models, class probabilities ROC curves included. regression models, predictions residuals vs. predicted plots included.","code":""},{"path":"/reference/make_prediction.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Make Predictions — make_prediction","text":"function uses caret, ggplot2, plotROC calculations plotting.","code":""},{"path":[]},{"path":"/reference/make_prediction.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Make Predictions — make_prediction","text":"Zakaria Kehel, Bancy Ngatia, Khadija Aziz, Zainab Azough, Chafik Analy, Khadija Aouzal","code":""},{"path":"/reference/make_prediction.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Make Predictions — make_prediction","text":"","code":"if (FALSE) { # \\dontrun{   # Example for classification model   data(\"septoriaDurumWC\")   knn.mod <- caret::train(ST_S ~ ., data = septoriaDurumWC, method = \"knn\")   testdata <- septoriaDurumWC   knn.pred <- make_prediction(newdata = testdata, y = \"ST_S\", positive = \"R\", model = knn.mod)   print(knn.pred)    # Example with SVM and ROC curve   svm.mod <- caret::train(ST_S ~ ., data = septoriaDurumWC, method = \"svmLinear2\",    metric = \"Accuracy\")   testdata <- septoriaDurumWC   svm.pred <- make_prediction(newdata = testdata, y = \"ST_S\", positive = \"R\", model = svm.mod,    auc = TRUE)   print(svm.pred) } # }"},{"path":"/reference/mapAccessions.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting Accessions on Map — mapAccessions","title":"Plotting Accessions on Map — mapAccessions","text":"function returns map points showing accessions collected.","code":""},{"path":"/reference/mapAccessions.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting Accessions on Map — mapAccessions","text":"","code":"mapAccessions(df, long, lat, y = NULL)"},{"path":"/reference/mapAccessions.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting Accessions on Map — mapAccessions","text":"df object class \"data.frame\" coordinates accessions target variable. long character. Column name df representing longitude. lat character. Column name df representing latitude. y Default: NULL, column name df representing target variable.","code":""},{"path":"/reference/mapAccessions.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting Accessions on Map — mapAccessions","text":"world map plotted points showing accessions collecting sites.","code":""},{"path":"/reference/mapAccessions.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plotting Accessions on Map — mapAccessions","text":"Khadija Aouzal, Zakaria Kehel","code":""},{"path":"/reference/mapAccessions.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plotting Accessions on Map — mapAccessions","text":"","code":"if (FALSE) { # \\dontrun{  # Loading FIGS subset for wheat sodicity resistance  data(FIGS)  # World Map showing locations of accessions  mapAccessions(df = FIGS, long = \"Longitude\", lat = \"Latitude\")    # Map plotting locations of accessions with points coloured   # based on a gradient scale of SodicityIndex values  mapAccessions(FIGS, long = \"Longitude\", lat = \"Latitude\",                 y = \"SodicityIndex\")  # Map plotting locations of accessions with points  # coloured based on levels of y   mapAccessions(FIGS, long = \"Longitude\", lat = \"Latitude\",   y = \"PopulationType\")  } # }"},{"path":"/reference/modelingSummary.html","id":null,"dir":"Reference","previous_headings":"","what":"Get modeling metrics — modelingSummary","title":"Get modeling metrics — modelingSummary","text":"modelingSummary automatic function modeling data, returns dataframe containing metrics modeling using five machine learning algorithms: KNN, SVM, RF, NNET, Bcart. function based spliData, tuneTrain, predict, getMetrics functions.","code":""},{"path":"/reference/modelingSummary.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get modeling metrics — modelingSummary","text":"","code":"modelingSummary(   data,   y,   p = 0.7,   length = 10,   control = \"repeatedcv\",   number = 10,   repeats = 10,   process = c(\"center\", \"scale\"),   summary = multiClassSummary,   positive,   parallelComputing = FALSE,   classtype,   ... )"},{"path":"/reference/modelingSummary.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get modeling metrics — modelingSummary","text":"data object class \"data.frame\" target variable predictor variables. y character. Target variable. p numeric. Proportion data used training. Default: 0.7 length integer. Number values output tuning parameter. search = \"random\" passed trainControl ..., becomes maximum number tuning parameter combinations generated random search. Default: 10. control character. Resampling method use. Choices include: \"boot\", \"boot632\", \"optimism_boot\", \"boot_all\", \"cv\", \"repeatedcv\", \"LOOCV\", \"LGOCV\", \"none\", \"oob\", timeslice, \"adaptive_cv\", \"adaptive_boot\", \"adaptive_LGOCV\". Default: \"repeatedcv\". See train specific details resampling methods. number integer. Number cross-validation folds number resampling iterations. Default: 10. repeats integer. Number folds repeated k-fold cross-validation \"repeatedcv\" chosen resampling method control. Default: 10. process character. Defines pre-processing transformation predictor variables done. Options : \"BoxCox\", \"YeoJohnson\", \"expoTrans\", \"center\", \"scale\", \"range\", \"knnImpute\", \"bagImpute\", \"medianImpute\", \"pca\", \"ica\", \"spatialSign\". See preProcess specific details pre-processing transformation. Default: c('center', 'scale'). summary expression. Computes performance metrics across resamples. numeric y, mean squared error R-squared calculated. factor y, overall accuracy Kappa calculated. See trainControl defaultSummary details specification summary options. Default: multiClassSummary. positive character. positive class target variable y factor. Usually, first level factor. parallelComputing logical. indicates whether also use parallel processing. Default: False classtype integer.indicates number classes traits. ... additional arguments passed createDataPartition, trainControl train functions package caret.","code":""},{"path":"/reference/modelingSummary.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get modeling metrics — modelingSummary","text":"dataframe contains metrics modeling five machine learning algorithms: KNN, SVM, RF, NNET, Bcart. tuneTrain relies package caret perform modeling.","code":""},{"path":"/reference/modelingSummary.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get modeling metrics — modelingSummary","text":"Types classification regression models available use tuneTrain can found using names(getModelInfo()). results given depend type model used.","code":""},{"path":[]},{"path":"/reference/modelingSummary.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get modeling metrics — modelingSummary","text":"Zakaria Kehel, Khadija Aziz","code":""},{"path":"/reference/modelingSummary.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get modeling metrics — modelingSummary","text":"","code":"if (FALSE) { # \\dontrun{  data(septoriaDurumWC)  models <- modelingSummary(data = septoriaDurumWC, y = \"ST_S\", positive = \"R\", classtype = 2) } # }"},{"path":"/reference/septoriaDurumWC.html","id":null,"dir":"Reference","previous_headings":"","what":"septoriaDurumWC — septoriaDurumWC","title":"septoriaDurumWC — septoriaDurumWC","text":"sample data including monthly data 3 climatic variables (tmin, tmax precipitation), 19 bioclimatic variables, evaluation Septoria Tritici","code":""},{"path":"/reference/septoriaDurumWC.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"septoriaDurumWC — septoriaDurumWC","text":"","code":"data(\"septoriaDurumWC\")"},{"path":"/reference/septoriaDurumWC.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"septoriaDurumWC — septoriaDurumWC","text":"200 sites durum wheat collection monthly climatic data evaluation Septoria Tritici.","code":""},{"path":"/reference/septoriaDurumWC.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"septoriaDurumWC — septoriaDurumWC","text":"","code":"if(interactive()){  #Load durum wheat data with septoria scores and climatic variables obtained from WorldClim database  data(\"septoriaDurumWC\") }"},{"path":"/reference/splitData.html","id":null,"dir":"Reference","previous_headings":"","what":"Splitting Data — splitData","title":"Splitting Data — splitData","text":"function splits Data Train Test Sets, returns list containing two data frames train test sets.","code":""},{"path":"/reference/splitData.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splitting Data — splitData","text":"","code":"splitData(data, seed = NULL, y, p, ...)"},{"path":"/reference/splitData.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splitting Data — splitData","text":"data object class \"data.frame\" target variable predictor variables. seed integer. Values random number generator. Default: NULL. y character. Target variable. p numeric. Proportion data used training. ... additional arguments passed createDataPartition function caret package control way data split.","code":""},{"path":"/reference/splitData.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splitting Data — splitData","text":"list two data frames: first train set, second test set.","code":""},{"path":"/reference/splitData.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Splitting Data — splitData","text":"splitData relies createDataPartition function caret package perform data split. y factor, sampling observations set done within levels y class distributions less balanced set. y numeric, data split groups based percentiles sampling done within subgroups. See createDataPartition details additional arguments can passed.","code":""},{"path":[]},{"path":"/reference/splitData.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Splitting Data — splitData","text":"Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/splitData.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splitting Data — splitData","text":"","code":"if (FALSE) { # \\dontrun{  # Split the data into 70/30 train and test sets for factor y  data(septoriaDurumWC)  split.data <- splitData(septoriaDurumWC, seed = 1234,                          y = 'ST_S', p = 0.7)   # Get training and test sets from list object returned  trainset <- split.data$trainset  testset <- split.data$testset } # }"},{"path":"/reference/tuneTrain.html","id":null,"dir":"Reference","previous_headings":"","what":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"Automatic function tuning training data, returns list containing model objects, data frame plot.","code":""},{"path":"/reference/tuneTrain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"","code":"tuneTrain(   data,   y,   p = 0.7,   method = \"knn\",   imbalanceMethod = NULL,   imbalanceThreshold = 0.2,   parallelComputing = FALSE,   control = \"repeatedcv\",   Length = 10,   number = 10,   repeats = 10,   process = c(\"center\", \"scale\"),   summary = multiClassSummary,   classProbs = FALSE,   ... )"},{"path":"/reference/tuneTrain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"data object class \"data.frame\" target variable predictor variables. y character. Target variable. p numeric. Proportion data used training. Default: 0.7 method character. Type model use classification regression. imbalanceMethod Method handling imbalanced data (\"\", \"\"). Default: NULL. imbalanceThreshold Threshold determine data imbalanced (numeric 0 0.4). Default: 0.2. parallelComputing logical. indicates whether also use parallel processing. Default: False control character. Resampling method use. Choices include: \"boot\", \"boot632\", \"optimism_boot\", \"boot_all\", \"cv\", \"repeatedcv\", \"LOOCV\", \"LGOCV\", \"none\", \"oob\", timeslice, \"adaptive_cv\", \"adaptive_boot\", \"adaptive_LGOCV\". Default: \"repeatedcv\". See train specific details resampling methods. Length integer. Number values output tuning parameter. search = \"random\" passed trainControl ..., becomes maximum number tuning parameter combinations generated random search. Default: 10. number integer. Number cross-validation folds number resampling iterations. Default: 10. repeats integer. Number folds repeated k-fold cross-validation \"repeatedcv\" chosen resampling method control. Default: 10. process character. Defines pre-processing transformation predictor variables done. Options : \"BoxCox\", \"YeoJohnson\", \"expoTrans\", \"center\", \"scale\", \"range\", \"knnImpute\", \"bagImpute\", \"medianImpute\", \"pca\", \"ica\", \"spatialSign\". See preProcess specific details pre-processing transformation. Default: c('center', 'scale'). summary expression. Computes performance metrics across resamples. numeric y, mean squared error R-squared calculated. factor y, overall accuracy Kappa calculated. See trainControl defaultSummary details specification summary options. Default: multiClassSummary. classProbs logical (default : TRUE assuming classification task). set FALSE regression tasks conjunction summary argument set \"defaultSummary\". See examples details. ... additional arguments passed createDataPartition, trainControl train functions package caret. classtype integer.indicates number classes traits.","code":""},{"path":"/reference/tuneTrain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"list object results tuning training model selected method, together predictions class probabilities. training test data sets obtained splitting data also returned addition model quality metrics preformance plots. y factor, class probabilities calculated class. y numeric, predicted values calculated. ROC curve created y factor. Otherwise, plot residuals versus predicted values created y numeric. tuneTrain relies packages caret, ggplot2 pROC perform modelling plotting.","code":""},{"path":"/reference/tuneTrain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"Types classification regression models available use tuneTrain can found using names(getModelInfo()). results given depend type model used. addition Model object, Model quality, Tuning training datasets,classification models, class probabilities ROC curve given results. regression models, Variable importance, predictions residuals versus predicted plot given. y converted either factor performing classification numeric performing regression specifying tuneTrain. Imbalance handling methods \"\" \"\" use ,respectively, upsample() downsample() caret subsampling methods.","code":""},{"path":[]},{"path":"/reference/tuneTrain.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"Chafik Analy, Khadija Aziz, Zakaria Kehel, Bancy Ngatia","code":""},{"path":"/reference/tuneTrain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Splitting the Data, Tuning and Training the models, and making predictions — tuneTrain","text":"","code":"if (FALSE) { # \\dontrun{ # Reading local test datasets data(DurumWheatDHEWC) data(BarleyRNOWC) data(septoriaDurumWC)  ## Binary classification of ST_S with balanced data tree.ST_S <- tuneTrain(data = as.data.frame(septoriaDurumWC),                      y =  'ST_S',                      method = 'treebag',                      summary = multiClassSummary,                      repeats = 3,                      classProbs = TRUE)  ## Binary classification of RNO with imbalanced data knn.RNO <- tuneTrain(data = BarleyRNOWC,                      y =  'RNO',                      method = 'knn',                      summary = multiClassSummary,                      imbalanceMethod =\"up\",                      imbalanceThreshold = 0.2,                      process = c(\"scale\",\"center\"),                      classProbs = TRUE,                      repeats = 3)                        ## Regression of DHE svm.DHE <- tuneTrain(data = DurumWheatDHEWC,                      y =  'DHE',                      method = 'svmLinear2',                      summary = defaultSummary,                      classProbs = FALSE,                      repeats = 3)  } # }"},{"path":"/reference/varimpPred.html","id":null,"dir":"Reference","previous_headings":"","what":"Variable Importance and Predictions — varimpPred","title":"Variable Importance and Predictions — varimpPred","text":"varimpPred calculates variable importance makes predictions. returns list containing data frame variable importance scores, predictions class probabilities, corresponding plots.","code":""},{"path":"/reference/varimpPred.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Variable Importance and Predictions — varimpPred","text":"","code":"varimpPred(   newdata,   y,   positive = NULL,   model,   scale = FALSE,   auc = FALSE,   predict = FALSE,   type = \"prob\",   ... )"},{"path":"/reference/varimpPred.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Variable Importance and Predictions — varimpPred","text":"newdata data frame. test dataset. y character string. name target variable. positive character string. positive class target variable y factor. Default: NULL. model model object. trained model returned caret::train. scale logical value. TRUE, scales variable importance values 0-100. Default: FALSE. auc logical value. TRUE, calculates area ROC curve (AUC) classification models. Default: FALSE. predict logical value. TRUE, calculates predictions class probabilities. Default: FALSE. type character string. type prediction, e.g., \"prob\" \"raw\". Default: \"prob\". ... Additional arguments passed caret::varImp.","code":""},{"path":"/reference/varimpPred.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Variable Importance and Predictions — varimpPred","text":"list containing variable importance scores, predictions, class probabilities, corresponding plots. classification models, class probabilities ROC curves included predict = TRUE. regression models, predictions residuals vs. predicted plots included predict = TRUE.","code":""},{"path":"/reference/varimpPred.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Variable Importance and Predictions — varimpPred","text":"function uses caret, ggplot2, plotROC calculations plotting. Variable importance calculated based type model. example, regression models, absolute value t-statistic parameter used importance calculation. classification models, variable importance score calculated class (except tree-based methods). See caret::varImp details.","code":""},{"path":[]},{"path":"/reference/varimpPred.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Variable Importance and Predictions — varimpPred","text":"Zakaria Kehel, Bancy Ngatia, Khadija Aziz, Zainab Azough, Chafik Analy","code":""},{"path":"/reference/varimpPred.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Variable Importance and Predictions — varimpPred","text":"","code":"if (FALSE) { # \\dontrun{   # Example for classification model   data(\"septoriaDurumWC\")   knn.mod <- caret::train(ST_S ~ ., data = septoriaDurumWC, method = \"knn\")   testdata <- septoriaDurumWC   knn.varimp <- varimpPred(newdata = testdata, y = \"ST_S\", positive = \"R\", model = knn.mod)   print(knn.varimp)    # Example with SVM and ROC curve   svm.mod <- caret::train(ST_S ~ ., data = septoriaDurumWC, method = \"svmLinear2\",    metric = \"Accuracy\")   testdata <- septoriaDurumWC   svm.varimp <- varimpPred(newdata = testdata, y = \"ST_S\", positive = \"R\", model = svm.mod,    auc = TRUE, predict = TRUE)   print(svm.varimp) } # }"}]
